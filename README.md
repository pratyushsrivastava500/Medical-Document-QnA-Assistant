# ğŸ¥ Medical Document Analysis Assistant

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.29.0-FF4B4B.svg)](https://streamlit.io)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

An intelligent AI-powered medical document analysis system using **Retrieval-Augmented Generation (RAG)** for accurate Q&A and professional medical report generation.

![Medical AI](https://img.shields.io/badge/AI-Medical%20Assistant-brightgreen)
![RAG Pipeline](https://img.shields.io/badge/RAG-Powered-orange)
![No Hallucination](https://img.shields.io/badge/Grounded-Responses-red)

---

## ğŸŒŸ Key Features

### ğŸ’¬ Interactive Q&A Mode
- **Multi-format Document Support**: PDF, Word, Excel, Images (OCR)
- **Google Drive Integration**: Direct file links without OAuth
- **Grounded Responses**: Every answer backed by source citations
- **Conversation Context**: Multi-turn dialogue with memory
- **Relevance Scoring**: Confidence indicators for answers
- **No Hallucinations**: Explicit responses when data unavailable

### ğŸ“Š Professional Report Generation
Create comprehensive medical reports with customizable sections:

| Section | Description |
|---------|-------------|
| ğŸ“ Introduction | Document overview and background |
| ğŸ”¬ Clinical Findings | Observations and test results |
| ğŸ©º Diagnosis | Medical conditions identified |
| ğŸ’Š Treatment Plan | Medications and interventions |
| ğŸ“‹ Summary | Comprehensive synthesis |

**Report Features:**
- âœ… Per-document generation
- âœ… Duplicate heading removal
- âœ… Professional PDF export
- âœ… Clean formatting
- âœ… Custom instructions support

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10 or higher
- pip package manager

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/yourusername/medical-document-assistant.git
cd medical-document-assistant
```

2. **Create virtual environment**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Configure environment variables**

Create a `.env` file in the project root:
```env
# Euriai API Configuration
EURIAI_API_KEY=your_api_key_here
EURIAI_MODEL=gpt-4.1-nano

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Optional: Tesseract OCR Path
TESSERACT_PATH=C:\Program Files\Tesseract-OCR\tesseract.exe
```

5. **Run the application**
```bash
streamlit run app.py
```

Visit `http://localhost:8501` in your browser.

---

## ğŸ“– Usage

### Document Upload

**Method 1: Local Files**
1. Use the sidebar file uploader
2. Select PDF, DOCX, XLSX, or image files
3. Wait for automatic processing

**Method 2: Google Drive**
1. Get a shareable link from Google Drive
2. Paste the link in the sidebar input
3. File is downloaded and cached locally

### Q&A Interaction

1. Switch to **"ğŸ’¬ Q&A Mode"** in the sidebar
2. Wait for documents to process
3. Ask questions in the chat interface
4. View answers with source citations
5. Ask follow-up questions with context

**Example Questions:**
```
â€¢ What is the patient's primary diagnosis?
â€¢ List all medications and dosages mentioned
â€¢ Summarize the treatment plan
â€¢ What were the lab test results?
â€¢ When was the last checkup?
```

### Report Generation

1. Switch to **"ğŸ“„ Report Generation"** in sidebar
2. Select desired sections (checkboxes)
3. Optionally add custom instructions
4. Click **"ğŸ”„ Generate Reports"**
5. Review generated content
6. Click **"ğŸ“¥ Download Report as PDF"**

---

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Streamlit UI                       â”‚
â”‚  (app.py - Chat Interface & Report Display)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Pipelineâ”‚   â”‚ Report Generator â”‚
â”‚  (Q&A Mode)  â”‚   â”‚  (Report Mode)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Document Processor â”‚
    â”‚  (Multi-format)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Vector Store       â”‚
    â”‚   (FAISS Index)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

- **Frontend**: Streamlit 1.29.0
- **LLM**: Euriai API (GPT-4.1-Nano)
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Vector DB**: FAISS (CPU-optimized)
- **Document Processing**: pypdf, python-docx, openpyxl, pytesseract
- **PDF Export**: ReportLab 4.0.7

### Project Structure

```
medical-document-assistant/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py              # Configuration settings
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ llm_client.py          # Euriai API client
â”‚   â”œâ”€â”€ rag_pipeline.py        # RAG implementation
â”‚   â”œâ”€â”€ report_generator.py    # Report generation
â”‚   â”œâ”€â”€ conversation_memory.py # Chat history
â”‚   â”œâ”€â”€ google_drive.py        # GDrive integration
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ document_processor.py  # Document parsing
â”‚   â”œâ”€â”€ embeddings.py          # Embedding generation
â”‚   â”œâ”€â”€ vector_store.py        # FAISS operations
â”‚   â”œâ”€â”€ pdf_exporter.py        # PDF report export
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploaded/              # User files
â”‚   â”œâ”€â”€ gdrive_cache/         # GDrive cache
â”‚   â””â”€â”€ vector_db/            # FAISS index
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_prompt.txt     # LLM instructions
â”‚   â””â”€â”€ user_prompt_template.txt
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ .env                     # Environment config
â””â”€â”€ README.md               # Documentation
```

---

## ğŸ”§ Configuration

### API Settings

Edit `.env` file:
```env
EURIAI_API_KEY=your_key_here
EURIAI_MODEL=gpt-4.1-nano
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
```

### Document Processing

Edit `config/config.py`:
```python
CHUNK_SIZE = 1000        # Text chunk size
CHUNK_OVERLAP = 200      # Overlap between chunks
TOP_K = 5               # Retrieved chunks per query
```

### Vector Store

- **Engine**: FAISS
- **Index Type**: Flat (exact search)
- **Metric**: Cosine similarity
- **Storage**: `data/vector_db/medical_documents_faiss.index`

---

## ğŸ¯ Core Features

### RAG Pipeline

1. **Document Ingestion**
   - Multi-format parsing (PDF, DOCX, XLSX, images)
   - Intelligent text chunking with overlap
   - Vector embedding generation

2. **Retrieval**
   - Semantic similarity search
   - Top-K relevant chunk selection
   - Relevance score calculation

3. **Generation**
   - Context-aware response generation
   - Source citation tracking
   - Grounded responses (no hallucination)

### Text Cleaning

Automatically removes:
- PDF/HTML headers and footers
- Hyphenation at line breaks
- Page numbers and metadata
- Broken words and fragments
- Irregular spacing and line breaks

### Report Features

- **Section-based Generation**: Independent processing
- **Context Integration**: Uses retrieved documents
- **Professional Formatting**: Clean markdown output
- **Duplicate Removal**: Single headings per section
- **PDF Export**: ReportLab with proper styling

### Error Handling

- âœ… API error detection (403, 500, etc.)
- âœ… No citations on error responses
- âœ… Graceful fallbacks for missing files
- âœ… Clear user feedback

---

## ğŸ“¦ Dependencies

### Core Libraries
```txt
streamlit==1.29.0           # Web framework
python-dotenv==1.0.0       # Environment config
euriai                     # LLM API client
langchain==0.1.0          # Text processing
sentence-transformers==2.3.1  # Embeddings
faiss-cpu==1.7.4          # Vector store
```

### Document Processing
```txt
pypdf==3.17.0             # PDF parsing
python-docx==1.1.0        # Word documents
openpyxl==3.1.2          # Excel files
pillow==10.1.0           # Image processing
pytesseract==0.3.10      # OCR
```

### Export & Utils
```txt
reportlab==4.0.7         # PDF generation
markdown==3.5.1          # Markdown parsing
pandas==2.1.4            # Data handling
numpy==1.26.2            # Numerical operations
```

See `requirements.txt` for complete list.

---

## ğŸ› Troubleshooting

### Common Issues

**OCR Not Working**
```bash
# Install Tesseract OCR
# Windows: Download from https://github.com/tesseract-ocr/tesseract
# Linux: sudo apt-get install tesseract-ocr
# Mac: brew install tesseract

# Set path in .env
TESSERACT_PATH=C:\Program Files\Tesseract-OCR\tesseract.exe
```

**API Errors (403 Forbidden)**
- Verify `EURIAI_API_KEY` is correct
- Check API quota and rate limits
- Ensure API key has proper permissions
- Citations will be hidden on API errors

**Documents Not Processing**
- Check file format is supported (PDF, DOCX, XLSX, images)
- Verify file is not corrupted
- Check console logs for detailed errors
- Ensure sufficient disk space

**PDF Export Issues**
```bash
# Reinstall reportlab
pip uninstall reportlab
pip install reportlab==4.0.7

# Check write permissions
# Windows: Check temp folder permissions
# Linux/Mac: Check /tmp permissions
```

---

## ğŸ”’ Security & Privacy

- âœ… Documents stored locally only
- âœ… No external data sharing (except LLM API)
- âœ… Google Drive files cached securely
- âœ… Session-based conversation memory
- âœ… Environment variables for credentials
- âœ… No user authentication required (local use)

---

## ğŸ“Š Performance

- **Vector Search**: Sub-second retrieval with FAISS
- **Document Processing**: ~2-5 seconds per document
- **Report Generation**: ~10-30 seconds per section
- **Memory Usage**: ~500MB-1GB depending on documents
- **Supported File Size**: Up to 50MB per document

---

## ğŸš§ Known Limitations

- OCR requires separate Tesseract installation
- Large files (>50MB) may process slowly
- Google Drive links must be publicly accessible
- Vector index not persistent across restarts
- Single-user local deployment only

---

## ğŸ”„ Roadmap

### Planned Features

- [ ] Persistent vector store
- [ ] Multi-language document support
- [ ] Advanced report visualizations
- [ ] Batch document processing
- [ ] Word/HTML export formats
- [ ] User authentication
- [ ] Multi-tenancy support
- [ ] Analytics dashboard
- [ ] API endpoints for integration
- [ ] Mobile-responsive UI

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Setup

```bash
# Clone your fork
git clone https://github.com/yourusername/medical-document-assistant.git

# Install development dependencies
pip install -r requirements.txt
pip install pytest black flake8

# Run tests
pytest tests/

# Format code
black .
```

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/medical-document-assistant/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/medical-document-assistant/discussions)
- **Email**: support@example.com

---

## ğŸ™ Acknowledgments

- Built with [Streamlit](https://streamlit.io)
- Powered by [Euriai](https://euron.one) LLM API
- Embeddings by [Sentence Transformers](https://www.sbert.net)
- Vector search by [FAISS](https://github.com/facebookresearch/faiss)

---

## â­ Star History

If this project helped you, please consider giving it a star! â­

---

**Made with â¤ï¸ for healthcare professionals**

*Disclaimer: This tool is for informational purposes only and should not replace professional medical advice, diagnosis, or treatment.*

- Internet connection for Groq API
- (Optional) Tesseract OCR for image processing

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/medical-document-assistant.git
cd medical-document-assistant

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Configuration

Create a `.env` file in the project root:

```env
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
GROQ_FALLBACK_MODEL=llama-3.1-8b-instant
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5
```

**Get your Groq API key**: [https://console.groq.com/keys](https://console.groq.com/keys)

### Run the Application

```bash
streamlit run app.py
```

The application will open in your browser at `http://localhost:8501`

---

## ğŸ“– Usage

### Q&A Mode

1. **Upload Documents**
   - Click sidebar â†’ Upload Documents
   - Support: PDF, DOCX, XLSX, PNG, JPG
   - Or paste Google Drive links

2. **Ask Questions**
   - Type your question in the chat
   - Get grounded answers with citations
   - Ask follow-up questions naturally

3. **View Citations**
   - Each answer includes source documents
   - Relevance scores for transparency
   - Full chunk content for verification

### Report Generation Mode

1. **Select Document** - Choose from uploaded files
2. **Choose Sections** - Select desired report sections
3. **Generate Report** - Click to create professional report
4. **Download** - Export as Markdown or PDF

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Streamlit Web Interface                      â”‚
â”‚  â€¢ File Upload  â€¢ Google Drive  â€¢ Chat  â€¢ Reports  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RAG Pipeline Service                    â”‚
â”‚  â€¢ Query Processing  â€¢ Context Building             â”‚
â”‚  â€¢ Response Generation  â€¢ Citation Extraction       â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚          â”‚              â”‚              â”‚
   â–¼          â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM â”‚  â”‚Vector  â”‚  â”‚Conversationâ”‚  â”‚ Document  â”‚
â”‚Groq â”‚  â”‚Store   â”‚  â”‚  Memory    â”‚  â”‚ Processor â”‚
â”‚70B  â”‚  â”‚FAISS   â”‚  â”‚  History   â”‚  â”‚Multi-fmt  â”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ›¡ï¸ No-Hallucination Safety

### Four-Layer Protection System

1. **Pre-LLM Relevance Filtering**
   - Filters queries with low relevance scores
   - Prevents irrelevant context from reaching LLM

2. **System Prompt (Global Rules)**
   - Emphatic instructions to use only provided information
   - Forbids external knowledge and assumptions

3. **User Prompt (Per-Query)**
   - Repeated enforcement of grounding rules
   - Clear failure handling for missing information

4. **Post-Generation Validation**
   - Detects "not available" responses
   - Returns empty citations when appropriate

---

## ğŸ”§ Tech Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **LLM** | Groq (llama-3.3-70b-versatile) | Response generation |
| **Embeddings** | Sentence Transformers | Semantic search |
| **Vector DB** | FAISS | Document retrieval |
| **UI** | Streamlit | Web interface |
| **PDF Export** | ReportLab | Professional reports |
| **Doc Processing** | pypdf, python-docx, openpyxl | Multi-format parsing |

---

## ğŸ“ Project Structure

```
medical-document-assistant/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env                            # Environment variables (create this)
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py                   # Configuration management
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_prompt.txt           # Q&A system prompt
â”‚   â”œâ”€â”€ user_prompt_template.txt    # Q&A user template
â”‚   â”œâ”€â”€ report_section_system_prompt.txt
â”‚   â”œâ”€â”€ report_section_user_prompt.txt
â”‚   â”œâ”€â”€ report_summary_system_prompt.txt
â”‚   â””â”€â”€ graphs_charts_user_prompt.txt
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ document_processor.py       # Multi-format parsing
â”‚   â”œâ”€â”€ pdf_exporter.py             # PDF generation
â”‚   â”œâ”€â”€ embeddings.py               # Embedding generation
â”‚   â””â”€â”€ vector_store.py             # FAISS operations
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ llm_client.py               # Groq LLM client
â”‚   â”œâ”€â”€ rag_pipeline.py             # RAG implementation
â”‚   â”œâ”€â”€ report_generator.py         # Report generation
â”‚   â”œâ”€â”€ google_drive.py             # Google Drive integration
â”‚   â””â”€â”€ conversation_memory.py      # Chat history
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ uploaded/                   # Uploaded documents
    â”œâ”€â”€ vector_db/                  # FAISS index
    â””â”€â”€ gdrive_cache/               # Cached Drive files
```

---

## ğŸ¯ Key Features Explained

### Retrieval-Augmented Generation (RAG)

1. **Document Ingestion**
   - Parse documents (PDF, Word, Excel, images)
   - Split into chunks (1000 chars, 200 overlap)
   - Generate embeddings
   - Store in FAISS vector database

2. **Question Answering**
   - Convert question to embedding
   - Search for similar document chunks
   - Build context from top-k results
   - Generate grounded response
   - Extract and display citations

3. **No Hallucination**
   - Only uses provided documents
   - Explicitly states when information unavailable
   - Shows source chunks for verification

---

## ğŸ”’ Security & Privacy

- âœ… API keys stored in `.env` (gitignored)
- âœ… Local document processing
- âœ… No data retention beyond session
- âœ… Public Google Drive links only (no OAuth)
- âœ… All processing happens locally except LLM calls

---

## ğŸ› ï¸ Customization

### Modify AI Behavior

Edit prompt files in `prompts/` folder:
- `system_prompt.txt` - Global AI behavior
- `user_prompt_template.txt` - Query template
- `report_section_system_prompt.txt` - Report writing style

### Adjust RAG Parameters

Edit `.env` file:
```env
CHUNK_SIZE=1000          # Size of document chunks
CHUNK_OVERLAP=200        # Overlap between chunks
TOP_K_RESULTS=5          # Number of chunks to retrieve
```

### Change LLM Model

Available Groq models:
- `llama-3.3-70b-versatile` (default, best accuracy)
- `llama-3.1-70b-versatile` (alternative)
- `llama-3.1-8b-instant` (faster, lower accuracy)

---

## ğŸ“š Documentation

For detailed documentation, see the main README.md file included in the project.

Topics covered:
- Detailed usage instructions
- Troubleshooting guide
- API configuration
- Testing procedures
- FAQ section

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“Š Project Stats

- **Code**: 2,500+ lines of Python
- **Modules**: 11 core modules
- **Features**: 15+ major features
- **Dependencies**: 28 packages
- **Safety Layers**: 4 hallucination prevention mechanisms
- **Supported Formats**: 5 (PDF, Word, Excel, PNG, JPG)

---

## ğŸ› Known Issues & Limitations

- OCR requires Tesseract installation for image processing
- Google Drive files must be publicly accessible
- Large documents may require increased memory
- Rate limits apply to Groq API (generous free tier)

---

## ğŸ—ºï¸ Roadmap

- [ ] Add support for more document formats (TXT, RTF, HTML)
- [ ] Implement user authentication system
- [ ] Add batch document processing
- [ ] Support for multiple languages
- [ ] Advanced visualization for graphs/charts
- [ ] Export to more formats (DOCX, HTML)
- [ ] Cloud deployment guides (AWS, Azure, GCP)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Groq** for fast LLM inference
- **Sentence Transformers** for embeddings
- **FAISS** for efficient vector search
- **Streamlit** for the amazing UI framework
- **ReportLab** for PDF generation

---

## ğŸ“§ Support

For questions, issues, or feature requests:
- Open an issue on GitHub
- Email: [your-email@example.com]
- Documentation: See main README.md

---

## â­ Star History

If you find this project helpful, please consider giving it a star! â­

---

**Built with â¤ï¸ for Healthcare Organizations**

Made with Python ğŸ | Powered by Groq ğŸš€ | Secured by RAG ğŸ›¡ï¸

